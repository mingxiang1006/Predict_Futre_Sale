{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "afMAannyFbLz"
   },
   "source": [
    "# Related Work\n",
    "Since sales are the life of any retail organization, forecasting sales in the retail space is crucial. Therefore, many researchers have carried out an accurate sales forecast and sales analysis. It has been found that a suitable predictive model that predicts sales can be found by looking at previous research on time series forecasting in finance using various machine learning algorithms. Because of the importance of prediction in many areas, many striking approaches have been developed. These methods are commonly referred to as statistical, machine learning, and hybrid methods. The most widely used models are time series analysis, autoregressive (AR) methods, autoregressive integrated moving average (ARIMA), and exponential smoothing methods. A time series forecasting and modeling is quite difficult due to other factors such as location, changing weather conditions, public events, holidays and festivals, it has a great impact on future demands, so the authors proposed to do Optimization of Grid Search (GSO) for forecasting sales. GSO is a technique that is assembled with the Extreme Gradient Boosting (Xgboost) algorithm. Xgboost is an extended version of Gradient Boosting Machines, which not only improves performance but also optimizes the system. The combination of GSO and Xgboost was used to select the best parameter for the predictive model after optimizing the various parameters of the Xgboost algorithm. Below is the workflow as the author creates the GSO-based future sales forecast:\n",
    "\n",
    "In this research, the author designed a predictive model using collaborative techniques with the Xgboost algorithm in the Big Mart dataset to predict future sales of a particular store or Big Mart store. Experimental analysis found that the technique gave a more accurate prediction with the lowest RMSE and lowest RMSE MAE for both training and testing. It was also concluded that the model performs better when hyper parameters are set. As part of the future work goal, the author sought to improve the accuracy using advanced techniques for optimizing hyper parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8LrPH8F3OZZH"
   },
   "source": [
    "# **3.Features Selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qai_3AHSDsjV"
   },
   "source": [
    "Below is the import Libraries that we use in features selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "2al40RFBD2QT"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score\n",
    "from math import sqrt\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from prettytable import PrettyTable\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.pipeline import Pipeline\n",
    "from matplotlib import pyplot\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "P2upRQfhE3WU"
   },
   "outputs": [],
   "source": [
    "#Loading our data\n",
    "train_df = pd.read_csv(\"/content/FeatureEngineering.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "uuCSwLSmIp05",
    "outputId": "39b6609d-fb61-4c0c-c563-85bf240fda51"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_cnt_day</th>\n",
       "      <th>lags: 1</th>\n",
       "      <th>lags: 2</th>\n",
       "      <th>lags: 3</th>\n",
       "      <th>lags: 4</th>\n",
       "      <th>lags: 5</th>\n",
       "      <th>lags: 6</th>\n",
       "      <th>lags: 7</th>\n",
       "      <th>lags: 8</th>\n",
       "      <th>lags: 9</th>\n",
       "      <th>lags: 10</th>\n",
       "      <th>lags: 11</th>\n",
       "      <th>shop_name</th>\n",
       "      <th>item_name</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>item_category_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>!Якутск Орджоникидзе, 56 фран</td>\n",
       "      <td>007: КООРДИНАТЫ «СКАЙФОЛЛ»</td>\n",
       "      <td>40</td>\n",
       "      <td>Кино - DVD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>482</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>!Якутск Орджоникидзе, 56 фран</td>\n",
       "      <td>007: КООРДИНАТЫ «СКАЙФОЛЛ» (BD)</td>\n",
       "      <td>37</td>\n",
       "      <td>Кино - Blu-Ray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>986</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>!Якутск Орджоникидзе, 56 фран</td>\n",
       "      <td>1+1</td>\n",
       "      <td>40</td>\n",
       "      <td>Кино - DVD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>987</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>!Якутск Орджоникидзе, 56 фран</td>\n",
       "      <td>1+1</td>\n",
       "      <td>40</td>\n",
       "      <td>Кино - DVD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1771</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>!Якутск Орджоникидзе, 56 фран</td>\n",
       "      <td>1+1 (BD)</td>\n",
       "      <td>37</td>\n",
       "      <td>Кино - Blu-Ray</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  date_block_num  ...  item_category_id  item_category_name\n",
       "0           0               1  ...                40          Кино - DVD\n",
       "1         482               1  ...                37      Кино - Blu-Ray\n",
       "2         986               0  ...                40          Кино - DVD\n",
       "3         987               1  ...                40          Кино - DVD\n",
       "4        1771               0  ...                37      Кино - Blu-Ray\n",
       "\n",
       "[5 rows x 20 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p_41FWKILeHK",
    "outputId": "c0eaaa27-5e42-463a-f1a2-866359ec4389"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 704112 entries, 0 to 704111\n",
      "Data columns (total 20 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   Unnamed: 0          704112 non-null  int64  \n",
      " 1   date_block_num      704112 non-null  int64  \n",
      " 2   shop_id             704112 non-null  int64  \n",
      " 3   item_id             704112 non-null  int64  \n",
      " 4   item_cnt_day        704112 non-null  float64\n",
      " 5   lags: 1             704112 non-null  float64\n",
      " 6   lags: 2             704112 non-null  float64\n",
      " 7   lags: 3             704112 non-null  float64\n",
      " 8   lags: 4             704112 non-null  float64\n",
      " 9   lags: 5             704112 non-null  float64\n",
      " 10  lags: 6             704112 non-null  float64\n",
      " 11  lags: 7             704112 non-null  float64\n",
      " 12  lags: 8             704112 non-null  float64\n",
      " 13  lags: 9             704112 non-null  float64\n",
      " 14  lags: 10            704112 non-null  float64\n",
      " 15  lags: 11            704112 non-null  float64\n",
      " 16  shop_name           704112 non-null  object \n",
      " 17  item_name           704112 non-null  object \n",
      " 18  item_category_id    704112 non-null  int64  \n",
      " 19  item_category_name  704112 non-null  object \n",
      "dtypes: float64(12), int64(5), object(3)\n",
      "memory usage: 107.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "rjG64lJtLtCk"
   },
   "outputs": [],
   "source": [
    "# Separating categorical data from numerical data\n",
    "train_categorical_data = train_df.select_dtypes(exclude=['int64', 'float','int32'])\n",
    "train_numerical_data = train_df.select_dtypes(include=['int64', 'float','int32'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "QfGBnBnIpMdI"
   },
   "outputs": [],
   "source": [
    "# Label Encode and Hot Encode for Categorical Columns\n",
    "# the category data here will be converted to numbers format\n",
    "le = LabelEncoder()\n",
    "train_categorical_data = train_categorical_data.apply(LabelEncoder().fit_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLvrdN3zwrIn"
   },
   "source": [
    "### **3.1  Regression Features Selection**\n",
    " We do the first features selection using pearson correlation, where the pearson correlation is a 2 variables that divide by the product of their standard deviations.Using pearson's correlation feature selection, it will do for numeric input and numeric output. When we execute the script, it gives a list of column sorted by the best features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wuD18P_Ju7fd",
    "outputId": "2deecac1-bd3b-4c47-b7c2-fe59a75b4fa2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(704112, 20)\n",
      "      Specs          Score\n",
      "8   lags: 1  945952.820544\n",
      "9   lags: 2  573826.787565\n",
      "10  lags: 3  491822.580126\n",
      "11  lags: 4  402102.171439\n",
      "12  lags: 5  378235.312794\n",
      "13  lags: 6  329039.954910\n"
     ]
    }
   ],
   "source": [
    "# define feature selection\n",
    "bestfeat = SelectKBest(score_func=f_regression, k='all')\n",
    "# apply feature selection\n",
    "X_selected = bestfeat.fit_transform(X, y)\n",
    "print(X_selected.shape)\n",
    "fit = bestfeat.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "#This code is to used for visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #name of the columns in dataframe\n",
    "print(featureScores.nlargest(6,'Score'))  #print 6 best features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y2XGmUWmTMs_"
   },
   "source": [
    "### **3.2 RFE Features Selection**\n",
    "Recursive Feature Elimination (RFE) is a one example of feature algorithm.  A machine learning dataset for classification or regression consists of rows associate in having columns like a surpass spreadsheet. Rows are referred as examples and the columns are referred to as options. Feature choose refers to techniques that select a set of the foremost relevant features (columns) for an information set. With fewer features, machine learning algorithms will run a lot of with efficiency (less abstraction or temporal complexity). Some machine learning algorithms may be fooled by unsuitable input characteristics, leading to worse prophetical performance. We choose RFE because we want to explore the number of designated options and wrapped algorithmic rule utilized by the RFE procedure. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9sui9m4LskVr",
    "outputId": "22a5e8ba-046b-49c9-d0a6-94f149ec9f97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: 0, Selected True, Rank: 1.0\n",
      "Column: 1, Selected False, Rank: 14.0\n",
      "Column: 2, Selected False, Rank: 13.0\n",
      "Column: 3, Selected False, Rank: 6.0\n",
      "Column: 4, Selected True, Rank: 1.0\n",
      "Column: 5, Selected False, Rank: 2.0\n",
      "Column: 6, Selected False, Rank: 15.0\n",
      "Column: 7, Selected True, Rank: 1.0\n",
      "Column: 8, Selected True, Rank: 1.0\n",
      "Column: 9, Selected False, Rank: 4.0\n",
      "Column: 10, Selected True, Rank: 1.0\n",
      "Column: 11, Selected False, Rank: 7.0\n",
      "Column: 12, Selected False, Rank: 5.0\n",
      "Column: 13, Selected False, Rank: 3.0\n",
      "Column: 14, Selected False, Rank: 9.0\n",
      "Column: 15, Selected False, Rank: 10.0\n",
      "Column: 16, Selected False, Rank: 8.0\n",
      "Column: 17, Selected False, Rank: 12.0\n",
      "Column: 18, Selected False, Rank: 11.0\n",
      "Column: 19, Selected False, Rank: 16.0\n"
     ]
    }
   ],
   "source": [
    "# Which features were selected by RFE\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# define dataset\n",
    "data_month = pd.read_csv(\"/content/FeatureEngineering.csv\")\n",
    "train_categorical_data = data_month.select_dtypes(exclude=['int64', 'float','int32'])\n",
    "train_numerical_data = data_month.select_dtypes(include=['int64', 'float','int32'])\n",
    "le = LabelEncoder()\n",
    "train_categorical_data = train_categorical_data.apply(LabelEncoder().fit_transform)\n",
    "\n",
    "# generate dataset\n",
    "X = pd.concat([train_categorical_data, train_numerical_data], axis=1)\n",
    "y = data_month['item_cnt_day']\n",
    "\n",
    "# define RFE\n",
    "rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=5)\n",
    "# fit RFE\n",
    "rfe.fit(X, y)\n",
    "# summarize all features\n",
    "for i in range(X.shape[1]):\n",
    "\tprint('Column: %d, Selected %s, Rank: %.1f' % (i, rfe.support_[i], rfe.ranking_[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ReYSWJqDgNO"
   },
   "source": [
    "When we execute this sript,the RFE have choose model, mean and standard deviations. Model that have higherst mean is Gradient Boosting Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "BYxhrTQlQUhf",
    "outputId": "7eadaf2f-d6a0-4250-b417-bd69ad08f1c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">lr 0.812 (0.038)\n",
      ">per 0.813 (0.034)\n",
      ">cart 0.812 (0.035)\n",
      ">rf 0.815 (0.037)\n",
      ">gbm 0.817 (0.032)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = pd.concat([train_categorical_data, train_numerical_data], axis=1)\n",
    "y = data_month['item_cnt_day']\n",
    "\n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "\tX, y = make_classification(n_samples=1000, n_features=5, n_informative=2, n_redundant=2, random_state=1)\n",
    "\treturn X, y\n",
    "\n",
    "# To find which list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\t# lr\n",
    "\trfe = RFE(estimator=LogisticRegression(), n_features_to_select=5)\n",
    "\tmodel = DecisionTreeClassifier()\n",
    "\tmodels['lr'] = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "\t# perceptron\n",
    "\trfe = RFE(estimator=Perceptron(), n_features_to_select=5)\n",
    "\tmodel = DecisionTreeClassifier()\n",
    "\tmodels['per'] = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "\t# cart\n",
    "\trfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=5)\n",
    "\tmodel = DecisionTreeClassifier()\n",
    "\tmodels['cart'] = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "\t# rf\n",
    "\trfe = RFE(estimator=RandomForestClassifier(), n_features_to_select=5)\n",
    "\tmodel = DecisionTreeClassifier()\n",
    "\tmodels['rf'] = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "\t# gbm\n",
    "\trfe = RFE(estimator=GradientBoostingClassifier(), n_features_to_select=5)\n",
    "\tmodel = DecisionTreeClassifier()\n",
    "\tmodels['gbm'] = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "\treturn models\n",
    "\n",
    "# To evaluate a  model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\treturn scores\n",
    "\n",
    "#get the data\n",
    "X, y = get_dataset()\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# To evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model, X, y)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4mUAT_BD6d1t"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NewRegressionModelling.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
